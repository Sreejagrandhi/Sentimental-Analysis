{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAExBsW07Pq2"
      },
      "source": [
        "#Exercise 7: Sentiment Analysis\n",
        " * Pre-process the text.\n",
        " * Convert the text into word embeddings.\n",
        " * Implement the classification network using LSTMs/ GRUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xztoWu1-dzQj"
      },
      "source": [
        "RNNS are used\n",
        "* In Natural Language Processing (NLP):\n",
        "  * Generate handwritten text\n",
        "  * Machine translation\n",
        "  * Speech recognition\n",
        "* In Computer Vision:\n",
        "  * Image captioning\n",
        "  * Image based question-answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q-hhIwV7Noe"
      },
      "outputs": [],
      "source": [
        "#Importing libraries and loading the dataset\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDTw2xQ87m3V",
        "outputId": "e05a2b6f-5101-4882-8dbe-1206a5b97c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 2s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ],
      "source": [
        "max_features = 20000\n",
        "maxlen1 = 80  # cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDCYyIzk55kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4ccf56-69ba-4b13-b43e-01030d386a14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDQo5D0qijh2",
        "outputId": "c57cbc7d-5da9-408b-a561-7a8fadc26c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data  (25000,)\n",
            "train_labels  (25000,)\n",
            "____________________________________________________________________________________________________\n",
            "test_data  (25000,)\n",
            "test_labels  (25000,)\n",
            "____________________________________________________________________________________________________\n",
            "Maximum value of a word index \n",
            "9999\n",
            "Maximum length num words of review in train \n",
            "2494\n"
          ]
        }
      ],
      "source": [
        "print(\"train_data \", x_train.shape)\n",
        "print(\"train_labels \", y_train.shape)\n",
        "print(\"_\"*100)\n",
        "print(\"test_data \", x_test.shape)\n",
        "print(\"test_labels \", y_test.shape)\n",
        "print(\"_\"*100)\n",
        "print(\"Maximum value of a word index \")\n",
        "print(max([max(sequence) for sequence in x_train]))\n",
        "print(\"Maximum length num words of review in train \")\n",
        "print(max([len(sequence) for sequence in x_train]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv3u5EhCiCT7",
        "outputId": "5275e011-1555-4040-cc5a-7ebac12f735e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 1s 1us/step\n",
            "? beautiful and touching movie rich colors great settings good acting and one of the most charming movies i have seen in a while i never saw such an interesting setting when i was in china my wife liked it so much she asked me to ? on and rate it so other would enjoy too\n"
          ]
        }
      ],
      "source": [
        "# See an actual review in words\n",
        "# Reverse from integers to words using the DICTIONARY (given by keras...need to do nothing to create it)\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "reverse_word_index = dict(\n",
        "[(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "decoded_review = ' '.join(\n",
        "[reverse_word_index.get(i - 3, '?') for i in x_train[123]])\n",
        "\n",
        "print(decoded_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8KcHvwNpwEm",
        "outputId": "ff5df32b-124f-4ea0-fe6e-3f181352f8e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189, 141, 550)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(x_train[0]),len(x_train[1]),len(x_train[2]),len(x_train[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBjKn5GNpWPA",
        "outputId": "288435f7-88bf-49f5-c49e-d58402ab1932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen1)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen1)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibp9-B0c8Fzp",
        "outputId": "6647c3ce-e2f5-484e-96bc-dec37debcbb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train...\n",
            "Epoch 1/15\n",
            "782/782 [==============================] - 350s 435ms/step - loss: 0.4339 - accuracy: 0.7967 - val_loss: 0.3580 - val_accuracy: 0.8415\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 329s 420ms/step - loss: 0.2846 - accuracy: 0.8832 - val_loss: 0.3668 - val_accuracy: 0.8355\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 332s 424ms/step - loss: 0.2082 - accuracy: 0.9194 - val_loss: 0.4015 - val_accuracy: 0.8199\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 320s 410ms/step - loss: 0.1571 - accuracy: 0.9412 - val_loss: 0.4570 - val_accuracy: 0.8214\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 320s 409ms/step - loss: 0.1184 - accuracy: 0.9557 - val_loss: 0.5161 - val_accuracy: 0.8185\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 326s 417ms/step - loss: 0.0863 - accuracy: 0.9688 - val_loss: 0.7605 - val_accuracy: 0.8183\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 322s 411ms/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 0.7748 - val_accuracy: 0.8138\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 323s 413ms/step - loss: 0.0572 - accuracy: 0.9801 - val_loss: 0.8019 - val_accuracy: 0.8088\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 329s 421ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.8329 - val_accuracy: 0.8061\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 329s 421ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.9350 - val_accuracy: 0.8152\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 326s 416ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.8740 - val_accuracy: 0.8134\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 324s 414ms/step - loss: 0.0291 - accuracy: 0.9910 - val_loss: 0.9198 - val_accuracy: 0.8108\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 326s 418ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.9937 - val_accuracy: 0.8167\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 325s 415ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 1.0148 - val_accuracy: 0.8099\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 318s 407ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 1.1115 - val_accuracy: 0.8106\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 1.1115 - accuracy: 0.8106\n",
            "Test score: 1.1115055084228516\n",
            "Test accuracy: 0.8106399774551392\n"
          ]
        }
      ],
      "source": [
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}